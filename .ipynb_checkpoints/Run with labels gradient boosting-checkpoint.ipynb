{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as tls\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamyee/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3044: DtypeWarning:\n",
      "\n",
      "Columns (32,84,87,88,100,110,117,124,125,128,130,131,165) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7                          1448\n",
       "8                          1427\n",
       "6                           765\n",
       "9                           677\n",
       "5                           627\n",
       "10 - Highly Satisfied       589\n",
       "3                           358\n",
       "4                           354\n",
       "1 - Highly Dissatisfied     167\n",
       "I prefer not to share       148\n",
       "2                           117\n",
       "Name: JobSatisfaction, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.set_option('display.max_rows', 300)\n",
    "\n",
    "survey = pd.read_csv('/Users/williamyee/Documents/Data Bootcamp/Classification-Project-DSjobs/Data/kaggle-survey-2017/multi_r_.csv', encoding = 'ISO-8859-1')\n",
    "\n",
    "list(survey.columns)\n",
    "\n",
    "survey.JobSatisfaction.value_counts()\n",
    "\n",
    "\n",
    "\n",
    "survey.head()\n",
    "\n",
    "survey.EmploymentStatus.unique()\n",
    "\n",
    "survey.groupby('EmploymentStatus').count()\n",
    "\n",
    "survey.UniversityImportance.value_counts()\n",
    "\n",
    "survey.JobSatisfaction.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [  survey.JobSatisfaction.isin(['7','8','9','10 - Highly Satisfied']),\n",
    "                survey.JobSatisfaction.isin(['1 - Highly Dissatisfied','2','3','4','5','6','I prefer not to share'])\n",
    "             ]\n",
    "choices = [1,0]\n",
    "survey['JobSatisfaction'] = np.select(conditions, choices, default=survey.JobSatisfaction)\n",
    "\n",
    "\n",
    "survey = survey[survey.JobSatisfaction.notna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6677, 229)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing = survey.isnull().sum()*100/len(survey)\n",
    "missing_value_df = pd.DataFrame({'columnname':survey.columns, 'percent_missing':percent_missing})\n",
    "#missing_value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing = survey.isnull().sum()*100/len(survey)\n",
    "missing_value_df = pd.DataFrame({'columnname':survey.columns, 'percent_missing':percent_missing})\n",
    "seventy_five_data = missing_value_df[missing_value_df.percent_missing<40]\n",
    "\n",
    "seventy_five_data\n",
    "\n",
    "survey_minimal_missing= survey[list(seventy_five_data.columnname)]\n",
    "\n",
    "survey_minimal_missing.reset_index(inplace=True)\n",
    "X = survey_minimal_missing.drop(columns = 'JobSatisfaction',axis =1)\n",
    "y = survey_minimal_missing['JobSatisfaction']\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 2536, 1: 4141})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = X.select_dtypes(include='object')\n",
    "X_cat = pd.DataFrame(X_cat,dtype ='str')\n",
    "imp_freq = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "X_cat_imputed = imp_freq.fit_transform(X_cat)\n",
    "X_cat_imputed = pd.DataFrame(data = X_cat_imputed, columns = X_cat.columns)\n",
    "\n",
    "from collections import defaultdict\n",
    "d = defaultdict(LabelEncoder)\n",
    "fit = X_cat_imputed.apply(lambda x: d[x.name].fit_transform(x))\n",
    "#fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = X.select_dtypes(include='float64')\n",
    "imp_freq = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "X_num_imputed = imp_freq.fit_transform(X_num)\n",
    "X_num_imputed = pd.DataFrame(data= X_num_imputed, columns = X_num.columns)\n",
    "\n",
    "scale = StandardScaler()\n",
    "X_num_imputed = scale.fit_transform(X_num_imputed)\n",
    "X_num_imputed = pd.DataFrame(data= X_num_imputed, columns = X_num.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(X_cat_imputed.shape[1]):\n",
    "#     print(X_cat.iloc[:,i].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imputed = pd.concat([fit,X_num_imputed],axis =1)\n",
    "colnames = X_imputed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =pd.Series(y, dtype ='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.concat([X_imputed,y])\n",
    "corrs = model_data.corr()\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "fig = sns.heatmap(corrs, square=True, cmap=\"RdBu_r\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_imputed.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(X_imputed, y, test_size=.2, random_state=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_train, y_train = ros.fit_sample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbm = GradientBoostingClassifier()\n",
    "gbm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter((gbm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(zip(list(gbm.feature_importances_),colnames)).sort_values(by = 0, ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid={\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.05, 0.075, 0.1],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'min_samples_split': [2, 3],\n",
    "    \"max_depth\":[40,50],\n",
    "    \"max_features\":[\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\"],\n",
    "    \"subsample\":[ 1.0],\n",
    "    \"n_estimators\":[125]\n",
    "    }\n",
    "clf = GridSearchCV(GradientBoostingClassifier(), parameter_grid, cv=5, n_jobs=-1,scoring = 'roc_auc', verbose= True)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf,open('gbmCV.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pickle.load(open('gbmCV.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# Run CV with 5 folds (Random Forest)\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [6, 15,20, 30,40],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'min_samples_split': [2, 3],\n",
    "    'n_estimators': [200, 400]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_grid = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, verbose=10, n_jobs=-1, scoring ='roc_auc')\n",
    "rf_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rf_grid,open('rfCV.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid = pickle.load(open('rfCV.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,rf_grid.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "440px",
    "left": "954px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
